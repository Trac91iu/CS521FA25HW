{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I work with Zichuan Li and Jian Cui."
      ],
      "metadata": {
        "id": "sSJL-pEXnHwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorboardX\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "# from tensorboardX import SummaryWriter\n",
        "\n",
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "## Dataloaders\n",
        "train_dataset = datasets.CIFAR10('cifar10_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.CIFAR10('cifar10_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "UpUUK_SHCVTe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "75ea1e96-c8c6-4ba6-dc31-c61594398814"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:06<00:00, 24.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tp_relu(x, delta=1.):\n",
        "    ind1 = (x < -1. * delta).float()\n",
        "    ind2 = (x > delta).float()\n",
        "    return .5 * (x + delta) * (1 - ind1) * (1 - ind2) + x * ind2\n",
        "\n",
        "def tp_smoothed_relu(x, delta=1.):\n",
        "    ind1 = (x < -1. * delta).float()\n",
        "    ind2 = (x > delta).float()\n",
        "    return (x + delta) ** 2 / (4 * delta) * (1 - ind1) * (1 - ind2) + x * ind2\n",
        "\n",
        "class Normalize(nn.Module):\n",
        "    def __init__(self, mu, std):\n",
        "        super(Normalize, self).__init__()\n",
        "        self.mu, self.std = mu, std\n",
        "\n",
        "    def forward(self, x):\n",
        "        return (x - self.mu) / self.std\n",
        "\n",
        "class IdentityLayer(nn.Module):\n",
        "    def forward(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "class PreActBlock(nn.Module):\n",
        "    '''Pre-activation version of the BasicBlock.'''\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, bn, learnable_bn, stride=1, activation='relu'):\n",
        "        super(PreActBlock, self).__init__()\n",
        "        self.collect_preact = True\n",
        "        self.activation = activation\n",
        "        self.avg_preacts = []\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes, affine=learnable_bn) if bn else IdentityLayer()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=not learnable_bn)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, affine=learnable_bn) if bn else IdentityLayer()\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=not learnable_bn)\n",
        "\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=not learnable_bn)\n",
        "            )\n",
        "\n",
        "    def act_function(self, preact):\n",
        "        if self.activation == 'relu':\n",
        "            act = F.relu(preact)\n",
        "        elif self.activation[:6] == '3prelu':\n",
        "            act = tp_relu(preact, delta=float(self.activation.split('relu')[1]))\n",
        "        elif self.activation[:8] == '3psmooth':\n",
        "            act = tp_smoothed_relu(preact, delta=float(self.activation.split('smooth')[1]))\n",
        "        else:\n",
        "            assert self.activation[:8] == 'softplus'\n",
        "            beta = int(self.activation.split('softplus')[1])\n",
        "            act = F.softplus(preact, beta=beta)\n",
        "        return act\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.act_function(self.bn1(x))\n",
        "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x  # Important: using out instead of x\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(self.act_function(self.bn2(out)))\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "class PreActResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, n_cls, cuda=True, half_prec=False,\n",
        "        activation='relu', fts_before_bn=False, normal='none'):\n",
        "        super(PreActResNet, self).__init__()\n",
        "        self.bn = True\n",
        "        self.learnable_bn = True  # doesn't matter if self.bn=False\n",
        "        self.in_planes = 64\n",
        "        self.avg_preact = None\n",
        "        self.activation = activation\n",
        "        self.fts_before_bn = fts_before_bn\n",
        "        if normal == 'cifar10':\n",
        "            self.mu = torch.tensor((0.4914, 0.4822, 0.4465)).view(1, 3, 1, 1)\n",
        "            self.std = torch.tensor((0.2471, 0.2435, 0.2616)).view(1, 3, 1, 1)\n",
        "        else:\n",
        "            self.mu = torch.tensor((0.0, 0.0, 0.0)).view(1, 3, 1, 1)\n",
        "            self.std = torch.tensor((1.0, 1.0, 1.0)).view(1, 3, 1, 1)\n",
        "            print('no input normalization')\n",
        "        if cuda:\n",
        "            self.mu = self.mu.cuda()\n",
        "            self.std = self.std.cuda()\n",
        "        if half_prec:\n",
        "            self.mu = self.mu.half()\n",
        "            self.std = self.std.half()\n",
        "\n",
        "        self.normalize = Normalize(self.mu, self.std)\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=not self.learnable_bn)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.bn = nn.BatchNorm2d(512 * block.expansion)\n",
        "        self.linear = nn.Linear(512*block.expansion, n_cls)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, self.bn, self.learnable_bn, stride, self.activation))\n",
        "            # layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "        for layer in [*self.layer1, *self.layer2, *self.layer3, *self.layer4]:\n",
        "            layer.avg_preacts = []\n",
        "\n",
        "        out = self.normalize(x)\n",
        "        out = self.conv1(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        if return_features and self.fts_before_bn:\n",
        "            return out.view(out.size(0), -1)\n",
        "        out = F.relu(self.bn(out))\n",
        "        if return_features:\n",
        "            return out.view(out.size(0), -1)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def PreActResNet18(n_cls, cuda=True, half_prec=False, activation='relu', fts_before_bn=False,\n",
        "    normal='none'):\n",
        "    #print('initializing PA RN-18 with act {}, normal {}'.format())\n",
        "    return PreActResNet(PreActBlock, [2, 2, 2, 2], n_cls=n_cls, cuda=cuda, half_prec=half_prec,\n",
        "        activation=activation, fts_before_bn=fts_before_bn, normal=normal)\n",
        "\n",
        "\n",
        "# intialize the model\n",
        "model = PreActResNet18(10, cuda=True, activation='softplus1').to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lLQlNRXlOTrc",
        "outputId": "41fb03a2-6f31-4bb3-a35e-70875f02a2ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no input normalization\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreActResNet(\n",
              "  (normalize): Normalize()\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pgd_linf_untargeted(model, x, labels, k, eps, eps_step):\n",
        "    model.eval()\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "    adv_x = x.clone().detach()\n",
        "    adv_x.requires_grad_(True)\n",
        "    for _ in range(k):\n",
        "        adv_x.requires_grad_(True)\n",
        "        model.zero_grad()\n",
        "        output = model(adv_x)\n",
        "        # TODO: Calculate the loss\n",
        "        loss = ce_loss(output, labels)\n",
        "        loss.backward()\n",
        "        # TODO: compute the adv_x\n",
        "        # find delta, clamp with eps\n",
        "\n",
        "        delta = eps_step * adv_x.grad.sign()\n",
        "        delta = torch.clamp(delta, min=-eps, max=eps)\n",
        "\n",
        "        adv_x = adv_x + delta\n",
        "        adv_x = torch.clamp(adv_x, min=0, max=1).detach()\n",
        "\n",
        "        adv_x = adv_x.detach()\n",
        "\n",
        "    return adv_x"
      ],
      "metadata": {
        "id": "kVi4B3hFOzv8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_linf_untargeted(model, x, labels, eps):\n",
        "    import torch\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    model.eval()\n",
        "    x_adv = x.clone().detach().requires_grad_(True)\n",
        "    logits = model(x_adv)\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    grad = torch.autograd.grad(loss, x_adv)[0]\n",
        "\n",
        "    # One FGSM step\n",
        "    x_adv = x_adv + eps * torch.sign(grad)\n",
        "\n",
        "    # Project to valid pixel range\n",
        "    x_adv = torch.clamp(x_adv, 0.0, 1.0).detach()\n",
        "    return x_adv"
      ],
      "metadata": {
        "id": "4o5lI9ONrxv1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adversarial training\n"
      ],
      "metadata": {
        "id": "76lcFhf8PBhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Re-init model with CIFAR-10 normalization handled inside the model\n",
        "model = PreActResNet18(10, cuda=use_cuda, activation='softplus1', normal='cifar10').to(device)\n",
        "\n",
        "# Standard training\n",
        "def train_standard(model, train_loader, epochs=2, lr=0.1, weight_decay=5e-4):\n",
        "    import torch.optim as optim\n",
        "    model.train()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[epochs//2, int(0.8*epochs)], gamma=0.1)\n",
        "    for ep in range(1, epochs+1):\n",
        "        total, correct, total_loss = 0, 0, 0.0\n",
        "        pbar = tqdm(train_loader, desc=f\"Standard Train Epoch {ep}/{epochs}\")\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total += x.size(0)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "            pbar.set_postfix(loss=total_loss/total, acc=correct/total)\n",
        "        scheduler.step()\n",
        "\n",
        "# Adversarial training using PGD\n",
        "def train_adversarial(model, train_loader, epochs=2, lr=0.1, weight_decay=5e-4, pgd_steps=10, eps=8/255.0, eps_step=2/255.0):\n",
        "    import torch.optim as optim\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[epochs//2, int(0.8*epochs)], gamma=0.1)\n",
        "    for ep in range(1, epochs+1):\n",
        "        total, correct, total_loss = 0, 0, 0.0\n",
        "        pbar = tqdm(train_loader, desc=f\"Adv Train Epoch {ep}/{epochs} (eps={eps:.4f})\")\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x_adv = pgd_linf_untargeted(model, x, y, k=pgd_steps, eps=eps, eps_step=eps_step)\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x_adv)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total += x.size(0)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "            pbar.set_postfix(loss=total_loss/total, acc=correct/total)\n",
        "        scheduler.step()\n",
        "\n",
        "def save_model(model, path):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def new_model():\n",
        "    return PreActResNet18(10, cuda=use_cuda, activation='softplus1', normal='cifar10').to(device)\n",
        "\n",
        "\n",
        "# Standard training model\n",
        "model_nat = new_model()\n",
        "train_standard(model_nat, train_loader, epochs=10)\n",
        "save_model(model_nat, f\"standard_model.pth\")\n",
        "\n",
        "# Experiments for (a) and (b)\n",
        "eps_values = [4/255.0, 8/255.0, 16/255.0]\n",
        "for eps in eps_values:\n",
        "    # Adversarial training model at this eps\n",
        "    model_adv = new_model()\n",
        "    train_adversarial(model_adv, train_loader, epochs=10, pgd_steps=10, eps=eps, eps_step=eps/4)\n",
        "    save_model(model_adv, f\"adv_pgd_eps_{int(eps*255)}_255_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4FodpSLbPKb4",
        "outputId": "d6e3ef0e-2b30-4c7f-8b7b-52cc8fbb980d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Standard Train Epoch 1/10: 100%|██████████| 782/782 [00:17<00:00, 43.50it/s, acc=0.446, loss=1.52]\n",
            "Standard Train Epoch 2/10: 100%|██████████| 782/782 [00:16<00:00, 48.18it/s, acc=0.608, loss=1.09]\n",
            "Standard Train Epoch 3/10: 100%|██████████| 782/782 [00:16<00:00, 47.28it/s, acc=0.664, loss=0.946]\n",
            "Standard Train Epoch 4/10: 100%|██████████| 782/782 [00:16<00:00, 48.70it/s, acc=0.695, loss=0.865]\n",
            "Standard Train Epoch 5/10: 100%|██████████| 782/782 [00:16<00:00, 48.75it/s, acc=0.715, loss=0.815]\n",
            "Standard Train Epoch 6/10: 100%|██████████| 782/782 [00:15<00:00, 49.96it/s, acc=0.784, loss=0.622]\n",
            "Standard Train Epoch 7/10: 100%|██████████| 782/782 [00:15<00:00, 50.16it/s, acc=0.8, loss=0.577]\n",
            "Standard Train Epoch 8/10: 100%|██████████| 782/782 [00:15<00:00, 49.27it/s, acc=0.809, loss=0.554]\n",
            "Standard Train Epoch 9/10: 100%|██████████| 782/782 [00:16<00:00, 48.55it/s, acc=0.827, loss=0.504]\n",
            "Standard Train Epoch 10/10: 100%|██████████| 782/782 [00:15<00:00, 49.31it/s, acc=0.833, loss=0.487]\n",
            "Adv Train Epoch 1/10 (eps=0.0157): 100%|██████████| 782/782 [01:17<00:00, 10.08it/s, acc=0.212, loss=2.12]\n",
            "Adv Train Epoch 2/10 (eps=0.0157): 100%|██████████| 782/782 [01:17<00:00, 10.04it/s, acc=0.256, loss=1.99]\n",
            "Adv Train Epoch 3/10 (eps=0.0157): 100%|██████████| 782/782 [01:17<00:00, 10.08it/s, acc=0.271, loss=1.95]\n",
            "Adv Train Epoch 4/10 (eps=0.0157): 100%|██████████| 782/782 [01:17<00:00, 10.06it/s, acc=0.278, loss=1.93]\n",
            "Adv Train Epoch 5/10 (eps=0.0157): 100%|██████████| 782/782 [01:17<00:00, 10.10it/s, acc=0.285, loss=1.92]\n",
            "Adv Train Epoch 6/10 (eps=0.0157): 100%|██████████| 782/782 [01:17<00:00, 10.12it/s, acc=0.299, loss=1.86]\n",
            "Adv Train Epoch 7/10 (eps=0.0157): 100%|██████████| 782/782 [01:17<00:00, 10.05it/s, acc=0.306, loss=1.84]\n",
            "Adv Train Epoch 8/10 (eps=0.0157): 100%|██████████| 782/782 [01:17<00:00, 10.08it/s, acc=0.312, loss=1.83]\n",
            "Adv Train Epoch 9/10 (eps=0.0157): 100%|██████████| 782/782 [01:17<00:00, 10.12it/s, acc=0.317, loss=1.81]\n",
            "Adv Train Epoch 10/10 (eps=0.0157): 100%|██████████| 782/782 [01:17<00:00, 10.12it/s, acc=0.317, loss=1.81]\n",
            "Adv Train Epoch 1/10 (eps=0.0314): 100%|██████████| 782/782 [01:17<00:00, 10.14it/s, acc=0.159, loss=2.25]\n",
            "Adv Train Epoch 2/10 (eps=0.0314): 100%|██████████| 782/782 [01:17<00:00, 10.15it/s, acc=0.182, loss=2.19]\n",
            "Adv Train Epoch 3/10 (eps=0.0314): 100%|██████████| 782/782 [01:16<00:00, 10.16it/s, acc=0.185, loss=2.18]\n",
            "Adv Train Epoch 4/10 (eps=0.0314): 100%|██████████| 782/782 [01:16<00:00, 10.16it/s, acc=0.19, loss=2.18]\n",
            "Adv Train Epoch 5/10 (eps=0.0314): 100%|██████████| 782/782 [01:16<00:00, 10.16it/s, acc=0.194, loss=2.18]\n",
            "Adv Train Epoch 6/10 (eps=0.0314): 100%|██████████| 782/782 [01:17<00:00, 10.15it/s, acc=0.193, loss=2.17]\n",
            "Adv Train Epoch 7/10 (eps=0.0314): 100%|██████████| 782/782 [01:17<00:00, 10.16it/s, acc=0.197, loss=2.16]\n",
            "Adv Train Epoch 8/10 (eps=0.0314): 100%|██████████| 782/782 [01:17<00:00, 10.15it/s, acc=0.202, loss=2.15]\n",
            "Adv Train Epoch 9/10 (eps=0.0314): 100%|██████████| 782/782 [01:17<00:00, 10.13it/s, acc=0.201, loss=2.15]\n",
            "Adv Train Epoch 10/10 (eps=0.0314): 100%|██████████| 782/782 [01:17<00:00, 10.14it/s, acc=0.203, loss=2.15]\n",
            "Adv Train Epoch 1/10 (eps=0.0627): 100%|██████████| 782/782 [01:17<00:00, 10.13it/s, acc=0.106, loss=2.34]\n",
            "Adv Train Epoch 2/10 (eps=0.0627): 100%|██████████| 782/782 [01:17<00:00, 10.15it/s, acc=0.119, loss=2.3]\n",
            "Adv Train Epoch 3/10 (eps=0.0627): 100%|██████████| 782/782 [01:17<00:00, 10.15it/s, acc=0.12, loss=2.29]\n",
            "Adv Train Epoch 4/10 (eps=0.0627): 100%|██████████| 782/782 [01:17<00:00, 10.15it/s, acc=0.122, loss=2.29]\n",
            "Adv Train Epoch 5/10 (eps=0.0627): 100%|██████████| 782/782 [01:17<00:00, 10.06it/s, acc=0.105, loss=2.3]\n",
            "Adv Train Epoch 6/10 (eps=0.0627): 100%|██████████| 782/782 [01:17<00:00, 10.07it/s, acc=0.0981, loss=2.3]\n",
            "Adv Train Epoch 7/10 (eps=0.0627): 100%|██████████| 782/782 [01:17<00:00, 10.14it/s, acc=0.0984, loss=2.3]\n",
            "Adv Train Epoch 8/10 (eps=0.0627): 100%|██████████| 782/782 [01:17<00:00, 10.14it/s, acc=0.0992, loss=2.3]\n",
            "Adv Train Epoch 9/10 (eps=0.0627): 100%|██████████| 782/782 [01:17<00:00, 10.15it/s, acc=0.1, loss=2.3]\n",
            "Adv Train Epoch 10/10 (eps=0.0627): 100%|██████████| 782/782 [01:17<00:00, 10.12it/s, acc=0.1, loss=2.3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(path):\n",
        "    model = PreActResNet18(10, cuda=use_cuda, activation='softplus1', normal='cifar10').to(device)\n",
        "    state = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n",
        "\n",
        "# Evaluation: standard accuracy\n",
        "@torch.no_grad()\n",
        "def evaluate_standard(model, loader):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        pred = logits.argmax(1)\n",
        "        total += x.size(0)\n",
        "        correct += (pred == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Evaluation: robust accuracy under PGD\n",
        "def evaluate_robust_pgd(model, loader, pgd_steps=10, eps=8/255.0, eps_step=2/255.0):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x_adv = pgd_linf_untargeted(model, x, y, k=pgd_steps, eps=eps, eps_step=eps_step)\n",
        "        with torch.no_grad():\n",
        "            logits = model(x_adv)\n",
        "            pred = logits.argmax(1)\n",
        "        total += x.size(0)\n",
        "        correct += (pred == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Evaluation: robust accuracy under FGSM\n",
        "def evaluate_robust_fgsm(model, loader, eps=8/255.0):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x_adv = fgsm_linf_untargeted(model, x, y, eps=eps)\n",
        "        with torch.no_grad():\n",
        "            logits = model(x_adv)\n",
        "            pred = logits.argmax(1)\n",
        "        total += x.size(0)\n",
        "        correct += (pred == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "eps_values = [0.0, 8/255.0]\n",
        "\n",
        "model_paths = [\n",
        "    \"standard_model.pth\",\n",
        "    \"adv_pgd_eps_4_255_model.pth\",\n",
        "    \"adv_pgd_eps_8_255_model.pth\",\n",
        "    \"adv_pgd_eps_16_255_model.pth\",\n",
        "]\n",
        "\n",
        "def report_model(path, eps_list, pgd_steps=20):\n",
        "    model = load_model(path)\n",
        "    print(f\"model path: {path}\")\n",
        "\n",
        "    for eps in eps_list:\n",
        "        # PGD robustness\n",
        "        acc = evaluate_robust_pgd(model, test_loader, pgd_steps=pgd_steps, eps=eps, eps_step=(eps/4 if eps>0 else 0.0))\n",
        "\n",
        "        if eps == 0.0:\n",
        "            print(f\"[eps=0, pgd_steps={pgd_steps:d}] Clean acc:  {acc:.4f}\")\n",
        "        else:\n",
        "            print(f\"[eps={eps:.5f}, pgd_steps={pgd_steps:d}] Robust acc: {acc:.4f}\")\n",
        "\n",
        "\n",
        "# Run reports\n",
        "for path in model_paths:\n",
        "    report_model(path, eps_values, 20)\n",
        "    report_model(path, eps_values, 10)\n",
        "    report_model(path, eps_values, 4)\n",
        "\n"
      ],
      "metadata": {
        "id": "CvlHJ2WcwSJN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7043545e-3e6b-45fa-c53b-9eb92cd4bd88"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model path: standard_model.pth\n",
            "[eps=0, pgd_steps=20] Clean acc:  0.8084\n",
            "[eps=0.03137, pgd_steps=20] Robust acc: 0.0000\n",
            "model path: standard_model.pth\n",
            "[eps=0, pgd_steps=10] Clean acc:  0.8084\n",
            "[eps=0.03137, pgd_steps=10] Robust acc: 0.0000\n",
            "model path: standard_model.pth\n",
            "[eps=0, pgd_steps=4] Clean acc:  0.8084\n",
            "[eps=0.03137, pgd_steps=4] Robust acc: 0.0000\n",
            "model path: adv_pgd_eps_4_255_model.pth\n",
            "[eps=0, pgd_steps=20] Clean acc:  0.5137\n",
            "[eps=0.03137, pgd_steps=20] Robust acc: 0.0239\n",
            "model path: adv_pgd_eps_4_255_model.pth\n",
            "[eps=0, pgd_steps=10] Clean acc:  0.5137\n",
            "[eps=0.03137, pgd_steps=10] Robust acc: 0.1550\n",
            "model path: adv_pgd_eps_4_255_model.pth\n",
            "[eps=0, pgd_steps=4] Clean acc:  0.5137\n",
            "[eps=0.03137, pgd_steps=4] Robust acc: 0.3611\n",
            "model path: adv_pgd_eps_8_255_model.pth\n",
            "[eps=0, pgd_steps=20] Clean acc:  0.3229\n",
            "[eps=0.03137, pgd_steps=20] Robust acc: 0.1166\n",
            "model path: adv_pgd_eps_8_255_model.pth\n",
            "[eps=0, pgd_steps=10] Clean acc:  0.3229\n",
            "[eps=0.03137, pgd_steps=10] Robust acc: 0.2072\n",
            "model path: adv_pgd_eps_8_255_model.pth\n",
            "[eps=0, pgd_steps=4] Clean acc:  0.3229\n",
            "[eps=0.03137, pgd_steps=4] Robust acc: 0.2714\n",
            "model path: adv_pgd_eps_16_255_model.pth\n",
            "[eps=0, pgd_steps=20] Clean acc:  0.1000\n",
            "[eps=0.03137, pgd_steps=20] Robust acc: 0.1000\n",
            "model path: adv_pgd_eps_16_255_model.pth\n",
            "[eps=0, pgd_steps=10] Clean acc:  0.1000\n",
            "[eps=0.03137, pgd_steps=10] Robust acc: 0.1000\n",
            "model path: adv_pgd_eps_16_255_model.pth\n",
            "[eps=0, pgd_steps=4] Clean acc:  0.1000\n",
            "[eps=0.03137, pgd_steps=4] Robust acc: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) (10 points) Try to attack the model you obtained after adversarial training using PGD and compare the effectiveness (based on the lowering of accuracy) with that of the original model. How effective is the model against an untargeted FGSM attack (one step of PGD)? Record your observations and try to explain them. Try different epsilon values against the adversarially trained models and report your observations.\n",
        "\n",
        "#### Description\n",
        "I tested PGD linf and FGSM on the four models with different eps (8/255, 4/255).\n",
        "\n",
        "#### Report: See below\n",
        "\n",
        "#### Observation\n",
        "1. The models are more robust under attack with eps=4/255, because the attack is weaker.\n",
        "2. The model adv_pgd_eps_4_255_model has the highest robust accuracy (0.43860) under PGD attack with eps=4/255.\n",
        "3. With the same eps value, the FGSM attack can be viewed as a single-step version of PGD. However, this does not mean that the model will exhibit greater robustness against FGSM. At eps = 8/255, the robustness of different models is nearly the same, while at eps = 4/255, the adversarially trained model performs better under PGD attacks. This may be because the model was specifically trained using PGD. Nevertheless, it still demonstrates reasonable defense capability against FGSM attacks."
      ],
      "metadata": {
        "id": "EPYyd4p8PKqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_on_single_attack(model, attack='pgd_linf', eps=0.1):\n",
        "    model.eval()\n",
        "    tot_test, tot_acc, tot_acc_adv = 0.0, 0.0, 0.0\n",
        "    for batch_idx, (x_batch, y_batch) in tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Evaluating\"):\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        if attack == 'pgd_linf':\n",
        "            # TODO: get x_adv untargeted pgd linf with eps, and eps_step=eps/4\n",
        "            x_adv = pgd_linf_untargeted(model, x_batch, y_batch, 4, eps, eps/4)\n",
        "        elif attack == 'fgsm':\n",
        "            x_adv = fgsm_linf_untargeted(model, x_batch, y_batch, eps)\n",
        "        # elif attack == 'pgd_l2':\n",
        "        #     # TODO: get x_adv untargeted pgd l2 with eps, and eps_step=eps/4\n",
        "        #     x_adv = pgd_l2_untargeted(model, x_batch, y_batch, 4, eps, eps/4)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        # get the testing accuracy and update tot_test and tot_acc\n",
        "        out_std = model(x_batch)\n",
        "        pred_std = torch.max(out_std, dim=1)[1]\n",
        "\n",
        "        out_adv = model(x_adv)\n",
        "        pred_adv = torch.max(out_adv, dim=1)[1]\n",
        "        tot_acc_adv += (pred_adv == y_batch).sum().item()\n",
        "        tot_acc += (pred_std == y_batch).sum().item()\n",
        "\n",
        "        tot_test += x_batch.size(0)\n",
        "\n",
        "    print('Standard accuracy %.5lf' % (tot_acc/tot_test))\n",
        "    print('Robust accuracy %.5lf' % (tot_acc_adv/tot_test), f'on {attack} attack with eps = {eps}')"
      ],
      "metadata": {
        "id": "uXT2-A7tqQpo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PGD linf with eps = 8/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on Linf attack with model 1 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 2 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 3 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 4 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)"
      ],
      "metadata": {
        "id": "_vxmCuhOtzqK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c0853e05-88a3-4d90-9fd8-5c9daeb0ed58"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:07<00:00, 21.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.80840\n",
            "Robust accuracy 0.00000 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:07<00:00, 21.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.51370\n",
            "Robust accuracy 0.36110 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:07<00:00, 21.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.32290\n",
            "Robust accuracy 0.27140 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:07<00:00, 21.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PGD linf with eps = 4/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on Linf attack with model 1 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 2 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 3 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 4 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)"
      ],
      "metadata": {
        "id": "t97KUdggt8BN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3989ed45-7c96-41f8-a19f-82227028c76c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:07<00:00, 21.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.80840\n",
            "Robust accuracy 0.00020 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:07<00:00, 21.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.51370\n",
            "Robust accuracy 0.43860 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:07<00:00, 21.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.32290\n",
            "Robust accuracy 0.29680 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:07<00:00, 21.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fgsm with eps = 8/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on fgsm attack with model 1 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 2 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 3 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 4 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "p0bbjk0hBUaq",
        "outputId": "d4656479-e0d6-4c83-f8e5-a480aa11e8d1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:03<00:00, 47.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.80840\n",
            "Robust accuracy 0.01190 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:03<00:00, 48.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.51370\n",
            "Robust accuracy 0.36240 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:03<00:00, 48.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.32290\n",
            "Robust accuracy 0.27110 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:03<00:00, 47.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fgsm with eps = 4/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on fgsm attack with model 1 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 2 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 3 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 4 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dXssudQRBOto",
        "outputId": "c92e0048-6439-4892-9004-5c43735f4c4a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:03<00:00, 48.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.80840\n",
            "Robust accuracy 0.02030 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:03<00:00, 48.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.51370\n",
            "Robust accuracy 0.43820 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:03<00:00, 48.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.32290\n",
            "Robust accuracy 0.29690 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:03<00:00, 49.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}